{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d1f252e",
   "metadata": {},
   "source": [
    "# Modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452de3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from sklearn import set_config\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 5000)\n",
    "pd.set_option(\"display.max_rows\", 101)\n",
    "pd.set_option('display.float_format', lambda x: '{:.2f}'.format(x))\n",
    "\n",
    "set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467b9b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from utils import RANDOM_STATE, TARGET\n",
    "\n",
    "\n",
    "X = pd.read_csv(\"./data/kaggle_train_set.csv\")\n",
    "\n",
    "# Ne gardons que les régions et les années de construction présentes dans le test set\n",
    "test = pd.read_csv(\"./data/kaggle_test_set.csv\")\n",
    "\n",
    "X = X[X.Neighborhood.isin(test.Neighborhood.unique())]\n",
    "# X = X[X.YearBuilt.isin(test.YearBuilt)]\n",
    "\n",
    "# Supprimons les outliers\n",
    "keep_columns = ['GrLivArea', 'TotalBsmtSF', '1stFlrSF', 'GarageArea']\n",
    "\n",
    "lof = LocalOutlierFactor(contamination=0.03)\n",
    "outliers_prediction = lof.fit_predict(X.loc[:, keep_columns])\n",
    "\n",
    "mask_non_outliers = outliers_prediction == 1\n",
    "X = X[mask_non_outliers]\n",
    "y = X.pop(TARGET)\n",
    "\n",
    "print(f\"\\nLa shape de X est {X.shape}\")\n",
    "print(f\"La shape de y est {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc38e9ca",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "\n",
    "\n",
    "    df['Age'] = 2011 - df['YearBuilt']\n",
    "    df['AgeRemod'] = 2011 - df['YearRemodAdd']\n",
    "\n",
    "    df[\"TotalArea\"] = df[\"GrLivArea\"] + df[\"TotalBsmtSF\"]\n",
    "\n",
    "    df[\"HasGarage\"] = df[\"GarageArea\"] > 0).astype(int)\n",
    "    df[\"HasFireplace\"] = (df[\"Fireplaces\"] > 0).astype(int)\n",
    "    df[\"HasBsmt\"] = df[\"TotalBsmtSF\"] > 0).astype(int)\n",
    "\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ed0e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FunctionTransformer, Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import Binarizer, PowerTransformer, OrdinalEncoder, RobustScaler\n",
    "\n",
    "\n",
    "def get_age(x):\n",
    "    return 2011 - x\n",
    "\n",
    "neighboors_categories = ['MeadowV', 'IDOTRR', 'BrDale', 'Edwards', 'BrkSide', 'OldTown', 'Blueste', 'Sawyer', 'SWISU', 'NAmes', 'NPkVill', 'Mitchel', 'SawyerW', 'Gilbert', 'Blmngtn', 'NWAmes', 'CollgCr', 'ClearCr', 'Crawfor', 'Somerst', 'Timber', 'Veenker', 'StoneBr', 'NoRidge', 'NridgHt']\n",
    "quality_order = ['Fa', 'TA', 'Gd', 'Ex']\n",
    "\n",
    "numerical_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('power_transformation', PowerTransformer(method='yeo-johnson', standardize=True)),\n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "categorical_encoding_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('encoder', OrdinalEncoder(categories=[neighboors_categories, quality_order, quality_order])),\n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('categorical', categorical_encoding_pipeline, ['Neighborhood', 'ExterQual', 'KitchenQual']),\n",
    "        ('numerical', numerical_pipeline, ['GarageCars', 'GrLivArea', 'TotalBsmtSF', 'LotArea']),\n",
    "        ('has_categories', Binarizer(threshold=0.0), ['Fireplaces', 'GarageArea', 'TotalBsmtSF']),\n",
    "        ('selected_passthrough', 'passthrough', ['OverallQual', 'FullBath']),\n",
    "        ('aging', FunctionTransformer(func=get_age), ['YearRemodAdd', 'YearBuilt'])\n",
    "    ],\n",
    "    remainder='drop',\n",
    ")\n",
    "\n",
    "\n",
    "preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3997f21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6fb32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "models = {\n",
    "    \"Ridge\": Ridge(random_state=RANDOM_STATE),\n",
    "    \"Random Forest\": RandomForestRegressor(random_state=RANDOM_STATE),\n",
    "    \"Gradient Boosting\": GradientBoostingRegressor(loss='huber', random_state=RANDOM_STATE),\n",
    "    \"LGBM\": LGBMRegressor(verbose=0, random_state=RANDOM_STATE),\n",
    "    \"SVR\": SVR(),\n",
    "    \"KNN\": KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessing),\n",
    "        ('regressor', TransformedTargetRegressor(\n",
    "            regressor=model,\n",
    "            func=np.log1p, inverse_func=np.expm1\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Validation croisée pour calculer la MAE\n",
    "    scores = cross_val_score(pipeline, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "    results[name] = -scores.mean()\n",
    "\n",
    "\n",
    "print(\"Résultats des modèles :\")\n",
    "for name, score in results.items():\n",
    "    print(f\"{name}: MAE = {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f094526",
   "metadata": {},
   "source": [
    "Gradient Boosting performe mieux que les autres. Gardons le pour la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5df36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Définir les hyperparamètres à optimiser\n",
    "    gb_params = dict(\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        # loss=trial.suggest_categorical(\"loss\", ['squared_error', 'absolute_error', 'huber', 'quantile']),\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        subsample=trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "        max_features=trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None]),\n",
    "        criterion=trial.suggest_categorical(\"criterion\", [\"friedman_mse\", \"squared_error\"])\n",
    "    )\n",
    "    \n",
    "    # Créer le pipeline avec le modèle et le prétraitement\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessing', preprocessing),\n",
    "        ('regressor', TransformedTargetRegressor(\n",
    "            regressor=GradientBoostingRegressor(random_state=RANDOM_STATE, **gb_params),\n",
    "            func=np.log1p, inverse_func=np.expm1\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Validation croisée pour calculer la MAE\n",
    "    scores = cross_val_score(pipeline, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "    return -scores.mean()\n",
    "\n",
    "# Lancer l'optimisation avec Optuna\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Afficher les meilleurs paramètres\n",
    "best_params = study.best_params\n",
    "print(\"Meilleurs hyperparamètres :\", best_params)\n",
    "print(\"Meilleurs scores: \", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e87401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement sur l´ensemble du dataset\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import TunedThresholdClassifierCV\n",
    "\n",
    "# best_params = {'max_depth': 5, 'learning_rate': 0.009739721675870424, 'n_estimators': 700, 'subsample': 0.5619157765347228, 'min_samples_split': 8, 'min_samples_leaf': 14, 'max_features': 'sqrt', 'criterion': 'squared_error'}\n",
    "\n",
    "estimator = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessing', preprocessing),\n",
    "        ('regressor', TransformedTargetRegressor(\n",
    "            regressor=GradientBoostingRegressor(random_state=RANDOM_STATE, loss='huber', **best_params),\n",
    "            func=np.log1p, inverse_func=np.expm1))\n",
    "        ]\n",
    ")\n",
    "\n",
    "estimator.set_params(**{'regressor__regressor__subsample': 1.0})\n",
    "\n",
    "estimator.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5405778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = estimator.predict(X)\n",
    "\n",
    "analyse = pd.DataFrame({'Prediction':y_pred, 'SalePrice': y.to_numpy()})\n",
    "analyse['PriceDifference'] = np.absolute(analyse.Prediction - analyse.SalePrice)\n",
    "analyse = analyse.join(X)\n",
    "analyse.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed16db9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse.PriceDifference.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6cc40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_error = analyse.query(\"PriceDifference > @analyse.PriceDifference.median()\")\n",
    "upper_error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5590158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "analysis_columns = [name for name in analyse.columns if name not in ['Prediction', 'SalePrice', 'PriceDifference']]\n",
    "fig, axs = plt.subplots(len(analysis_columns), 1, figsize=(12, 40))\n",
    "for i, name in enumerate(analysis_columns):\n",
    "    sns.histplot(analyse, x=name, ax=axs[i])\n",
    "fig.suptitle(\"Distribution des cas > médiane de Absolute Error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d875d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "test = pd.read_csv(\"./data/kaggle_test_set.csv\")\n",
    "\n",
    "# Prédictions\n",
    "result = estimator.predict(test)\n",
    "\n",
    "# Créer le DataFrame de soumission avec \"ID\" comme index\n",
    "submission_df = pd.DataFrame(result, columns=[\"SalePrice\"], index=test.index)\n",
    "submission_df.index.name = \"ID\"  # Renommer l'index en \"ID\"\n",
    "\n",
    "# Sauvegarder le fichier CSV\n",
    "submission_df.to_csv(\"./data/submission.csv\")\n",
    "\n",
    "# Vérification\n",
    "check_df = pd.read_csv(\"./data/submission.csv\", index_col='ID')\n",
    "check_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a87c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import io\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "from utils import sauvegarder_model\n",
    "\n",
    "competition = \"regression-prediction-prix-immobilier\"\n",
    "\n",
    "\n",
    "def all_status_complete(df):\n",
    "    return all(df['status'].isin(['SubmissionStatus.ERROR', 'SubmissionStatus.COMPLETE']))\n",
    "\n",
    "# Fonction pour relancer le subprocess et récupérer les données\n",
    "def relaunch_subprocess():\n",
    "    result = subprocess.run(\n",
    "        [\"kaggle\", \"competitions\", \"submissions\", \"-v\", \"-c\",  competition],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "        )\n",
    "    return result.stdout\n",
    "\n",
    "\n",
    "\n",
    "now = str(datetime.now())\n",
    "# Timeout de 1 minute\n",
    "timeout = 60  # en secondes\n",
    "start_time = time.time()\n",
    "\n",
    "data = None\n",
    "\n",
    "if SUBMIT:= True:\n",
    "    file_path = \"./data/submission.csv\"\n",
    "    message = f\"timestamp: {now}, Utilisation des paramètres: {estimator.get_params()}\"\n",
    "\n",
    "    result = subprocess.run(\n",
    "        [\"kaggle\", \"competitions\", \"submit\", \"-c\", competition, \"-f\", file_path, \"-m\", message],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    print(\"⚒️\", result.stdout)\n",
    "\n",
    "    if result.stderr != '':\n",
    "        print(result.stderr)\n",
    "    data = None\n",
    "\n",
    "    while True:\n",
    "        # Récupérer les données depuis le subprocess\n",
    "        stdout_data = relaunch_subprocess()\n",
    "        \n",
    "        # Convertir les données en DataFrame\n",
    "        data = pd.read_csv(io.StringIO(stdout_data), parse_dates=['date'])\n",
    "        \n",
    "        # Vérifier si tous les statuts sont complets\n",
    "        if all_status_complete(data):\n",
    "            break\n",
    "        \n",
    "        # Vérification du timeout\n",
    "        if time.time() - start_time > timeout:\n",
    "            print(\"\")\n",
    "            raise RuntimeError(\"imeout atteint. Arrêt de la boucle.\")\n",
    "        \n",
    "        # Pause avant la prochaine vérification\n",
    "        time.sleep(20)  # Pause de 20 secondes\n",
    "\n",
    "    if data is not None and all_status_complete(data):\n",
    "        # Trouver la ligne avec la date la plus récente\n",
    "        most_recent = data.sort_values('date', ascending=False).iloc[0]\n",
    "        recent_score = most_recent['publicScore']\n",
    "        best_score = data['publicScore'].min()\n",
    "\n",
    "        if recent_score == best_score:\n",
    "            print(f\"🥳 Nouveau meilleur score : {recent_score:.5f}\")\n",
    "            sauvegarder_model(estimator, timestamp=now, only_latest=False)\n",
    "        else:\n",
    "            print(f\"❌ Bien essayé mais c´est moins bon. Score: {recent_score:.5f}. Meilleur score : {best_score:.5f}\")\n",
    "\n",
    "if not SUBMIT:\n",
    "    sauvegarder_model(estimator, timestamp=now, only_latest=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regression-prediction-prix-immobilier-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
