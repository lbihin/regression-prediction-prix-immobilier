{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "908b1e39",
   "metadata": {},
   "source": [
    "# Regression Prix Immobilier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "764d0632",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 5000)\n",
    "pd.set_option(\"display.max_rows\", 101)\n",
    "pd.set_option('display.float_format', lambda x: '{:.2f}'.format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-analysis-title",
   "metadata": {},
   "source": [
    "# üìä Analyse Simplifi√©e des Quartiers \"Bad\" (MAE √âlev√©e)\n",
    "\n",
    "Cette section contient l'analyse refactoris√©e et simplifi√©e pour identifier pourquoi certains quartiers ont une erreur de pr√©diction √©lev√©e (MAE). \n",
    "\n",
    "**Structure en 5 cellules comme demand√© :**\n",
    "1. **Contexte et pr√©paration** : Chargement des donn√©es et d√©finition des groupes de comparaison\n",
    "2. **M√©triques simples (ŒîMAE) et tableaux r√©cap** : Calcul des MAE pour les caract√©ristiques num√©riques et cat√©gorielles  \n",
    "3. **Graphiques lisibles pour les TOP_K features (num√©riques)** : Visualisation des m√©dianes de SalePrice par quantile\n",
    "4. **Graphiques lisibles pour les TOP_K features (cat√©gorielles)** : Visualisation des moyennes de SalePrice par modalit√©\n",
    "5. **Pistes d'action, par quartier \"bad\"** : Rapport textuel sur les caract√©ristiques qui p√©nalisent la MAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "context-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELLULE 1 ‚Äî CONTEXTE ET PR√âPARATION =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des graphiques pour plus de lisibilit√©\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Charger les donn√©es d'analyse\n",
    "df = pd.read_csv(\"./data/kaggle_train_set.csv\")\n",
    "print(f\"üìä Dataset charg√© : {df.shape[0]} √©chantillons, {df.shape[1]} variables\")\n",
    "\n",
    "# Entra√Æner un mod√®le simple pour calculer les MAE par quartier\n",
    "features_for_model = ['OverallQual', 'YearBuilt', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', \n",
    "                     'FullBath', 'TotRmsAbvGrd', 'Fireplaces', 'YearRemodAdd', 'GarageArea', '1stFlrSF']\n",
    "\n",
    "# Encoder les variables cat√©gorielles pour le mod√®le\n",
    "df_model = df.copy()\n",
    "le_neighb = LabelEncoder()\n",
    "le_exter = LabelEncoder() \n",
    "le_kitchen = LabelEncoder()\n",
    "\n",
    "df_model['Neighborhood_enc'] = le_neighb.fit_transform(df_model['Neighborhood'])\n",
    "df_model['ExterQual_enc'] = le_exter.fit_transform(df_model['ExterQual'])\n",
    "df_model['KitchenQual_enc'] = le_kitchen.fit_transform(df_model['KitchenQual'])\n",
    "\n",
    "X = df_model[features_for_model + ['Neighborhood_enc', 'ExterQual_enc', 'KitchenQual_enc']]\n",
    "y = df_model['SalePrice']\n",
    "\n",
    "# Diviser les donn√©es\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Entra√Æner le mod√®le\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Faire les pr√©dictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculer la MAE globale\n",
    "mae_global = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"üéØ MAE globale du mod√®le : {mae_global:,.0f}$\")\n",
    "\n",
    "# Cr√©er un DataFrame avec les r√©sultats de test\n",
    "test_results = pd.DataFrame({\n",
    "    'Neighborhood': df.iloc[X_test.index]['Neighborhood'].values,\n",
    "    'SalePrice_true': y_test.values,\n",
    "    'SalePrice_pred': y_pred,\n",
    "    'residual': y_test.values - y_pred\n",
    "})\n",
    "\n",
    "# Calculer la MAE par quartier\n",
    "mae_by_neighborhood = test_results.groupby('Neighborhood').apply(\n",
    "    lambda x: mean_absolute_error(x['SalePrice_true'], x['SalePrice_pred'])\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print(f\"\\nüèòÔ∏è  Quartiers avec MAE la plus √©lev√©e :\")\n",
    "print(mae_by_neighborhood.head(8))\n",
    "\n",
    "# D√©finir les quartiers \"bad\" (MAE > percentile 75)\n",
    "mae_threshold = mae_by_neighborhood.quantile(0.75)\n",
    "bad_mae_region = mae_by_neighborhood[mae_by_neighborhood > mae_threshold].index.tolist()\n",
    "print(f\"\\nüö® Quartiers 'BAD' identifi√©s (MAE > {mae_threshold:,.0f}$) :\")\n",
    "for region in bad_mae_region:\n",
    "    count = df[df['Neighborhood'] == region].shape[0]\n",
    "    print(f\"   - {region}: MAE = {mae_by_neighborhood[region]:,.0f}$ ({count} √©chantillons)\")\n",
    "\n",
    "# Cr√©er le flag pour l'analyse comparative\n",
    "bad_list = [n for n in bad_mae_region if n in df[\"Neighborhood\"].unique()]\n",
    "df[\"__is_bad__\"] = df[\"Neighborhood\"].isin(bad_list)\n",
    "\n",
    "print(f\"\\n‚úÖ Pr√©paration termin√©e. {len(bad_list)} quartiers 'bad' identifi√©s pour analyse.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELLULE 2 ‚Äî M√âTRIQUES SIMPLES (ŒîMAE) ET TABLEAUX R√âCAP =====\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    \"\"\"Fonction MAE simple avec gestion des cas limites\"\"\"\n",
    "    if len(y_true) == 0 or len(y_pred) == 0:\n",
    "        return 0\n",
    "    return np.mean(np.abs(np.array(y_true) - np.array(y_pred)))\n",
    "\n",
    "print(\"üìã CALCUL DES ŒîMAE POUR TOUTES LES CARACT√âRISTIQUES\\n\")\n",
    "\n",
    "# === FEATURES NUM√âRIQUES ===\n",
    "num_features = ['OverallQual', 'YearBuilt', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', \n",
    "                'FullBath', 'TotRmsAbvGrd', 'Fireplaces', 'YearRemodAdd', 'GarageArea', \n",
    "                'LotArea', '1stFlrSF']\n",
    "\n",
    "# Calculer la pr√©diction \"na√Øve\" : m√©diane globale par quartile de feature\n",
    "rows_num = []\n",
    "for f in num_features:\n",
    "    try:\n",
    "        # Diviser en quartiles (g√©rer les duplicates pour les features √† peu de valeurs uniques)\n",
    "        df['quartile'] = pd.qcut(df[f], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'], duplicates='drop')\n",
    "        \n",
    "        # Pour chaque quartile, pr√©dire avec la m√©diane du quartile\n",
    "        predictions_out = []\n",
    "        predictions_bad = []\n",
    "        actual_out = []\n",
    "        actual_bad = []\n",
    "        \n",
    "        for quartile in df['quartile'].unique():\n",
    "            if pd.isna(quartile):\n",
    "                continue\n",
    "            quartile_data = df[df['quartile'] == quartile]\n",
    "            median_price = quartile_data['SalePrice'].median()\n",
    "            \n",
    "            # S√©parer quartiers \"bad\" vs \"good\"\n",
    "            out_data = quartile_data[~quartile_data['__is_bad__']]\n",
    "            bad_data = quartile_data[quartile_data['__is_bad__']]\n",
    "            \n",
    "            if len(out_data) > 0:\n",
    "                predictions_out.extend([median_price] * len(out_data))\n",
    "                actual_out.extend(out_data['SalePrice'].tolist())\n",
    "            \n",
    "            if len(bad_data) > 0:\n",
    "                predictions_bad.extend([median_price] * len(bad_data))\n",
    "                actual_bad.extend(bad_data['SalePrice'].tolist())\n",
    "        \n",
    "        # Calculer les MAE\n",
    "        mae_out = mae(actual_out, predictions_out) if actual_out else 0\n",
    "        mae_bad = mae(actual_bad, predictions_bad) if actual_bad else 0\n",
    "        delta_mae = mae_bad - mae_out\n",
    "        \n",
    "        rows_num.append({\n",
    "            \"feature\": f,\n",
    "            \"mae_out\": mae_out,\n",
    "            \"mae_bad\": mae_bad,\n",
    "            \"delta_mae\": delta_mae\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Attention avec {f}: {e}\")\n",
    "        # Ajouter une entr√©e par d√©faut\n",
    "        rows_num.append({\n",
    "            \"feature\": f,\n",
    "            \"mae_out\": 0,\n",
    "            \"mae_bad\": 0,\n",
    "            \"delta_mae\": 0\n",
    "        })\n",
    "\n",
    "num_summary = pd.DataFrame(rows_num).sort_values(\"delta_mae\", ascending=False)\n",
    "\n",
    "print(\"üî¢ R√âSUM√â FEATURES NUM√âRIQUES (Top 8 ŒîMAE)\")\n",
    "print(\"=\"*60)\n",
    "display(num_summary.head(8).round(0))\n",
    "\n",
    "# === FEATURES CAT√âGORIELLES ===\n",
    "cat_features = ['ExterQual', 'KitchenQual', 'Neighborhood']\n",
    "\n",
    "rows_cat = []\n",
    "for f in cat_features:\n",
    "    try:\n",
    "        # Pour chaque modalit√©, pr√©dire avec la moyenne de cette modalit√©\n",
    "        predictions_out = []\n",
    "        predictions_bad = []\n",
    "        actual_out = []\n",
    "        actual_bad = []\n",
    "        \n",
    "        for category in df[f].unique():\n",
    "            cat_data = df[df[f] == category]\n",
    "            mean_price = cat_data['SalePrice'].mean()\n",
    "            \n",
    "            # S√©parer quartiers \"bad\" vs \"good\"\n",
    "            out_data = cat_data[~cat_data['__is_bad__']]\n",
    "            bad_data = cat_data[cat_data['__is_bad__']]\n",
    "            \n",
    "            if len(out_data) > 0:\n",
    "                predictions_out.extend([mean_price] * len(out_data))\n",
    "                actual_out.extend(out_data['SalePrice'].tolist())\n",
    "            \n",
    "            if len(bad_data) > 0:\n",
    "                predictions_bad.extend([mean_price] * len(bad_data))\n",
    "                actual_bad.extend(bad_data['SalePrice'].tolist())\n",
    "        \n",
    "        # Calculer les MAE\n",
    "        mae_out = mae(actual_out, predictions_out) if actual_out else 0\n",
    "        mae_bad = mae(actual_bad, predictions_bad) if actual_bad else 0\n",
    "        delta_mae = mae_bad - mae_out\n",
    "        \n",
    "        rows_cat.append({\n",
    "            \"feature\": f,\n",
    "            \"mae_out\": mae_out,\n",
    "            \"mae_bad\": mae_bad,\n",
    "            \"delta_mae\": delta_mae\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Attention avec {f}: {e}\")\n",
    "        rows_cat.append({\n",
    "            \"feature\": f,\n",
    "            \"mae_out\": 0,\n",
    "            \"mae_bad\": 0,\n",
    "            \"delta_mae\": 0\n",
    "        })\n",
    "\n",
    "cat_summary = pd.DataFrame(rows_cat).sort_values(\"delta_mae\", ascending=False)\n",
    "\n",
    "print(\"\\nüè∑Ô∏è  R√âSUM√â FEATURES CAT√âGORIELLES\")\n",
    "print(\"=\"*60)\n",
    "display(cat_summary.round(0))\n",
    "\n",
    "print(f\"\\nüí° INSIGHTS ŒîMAE :\")\n",
    "print(f\"   ‚Ä¢ Feature num√©rique la plus probl√©matique : {num_summary.iloc[0]['feature']} (ŒîMAE: {num_summary.iloc[0]['delta_mae']:+,.0f}$)\")\n",
    "print(f\"   ‚Ä¢ Feature cat√©gorielle la plus probl√©matique : {cat_summary.iloc[0]['feature']} (ŒîMAE: {cat_summary.iloc[0]['delta_mae']:+,.0f}$)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "top-numerical-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELLULE 3 ‚Äî GRAPHIQUES LISIBLES POUR LES TOP_K FEATURES (NUM√âRIQUES) =====\n",
    "\n",
    "TOP_K = 6  # Nombre de features √† visualiser\n",
    "top_num_features = num_summary.head(TOP_K)['feature'].tolist()\n",
    "\n",
    "print(f\"üìä VISUALISATION DES {TOP_K} FEATURES NUM√âRIQUES LES PLUS PROBL√âMATIQUES\\n\")\n",
    "\n",
    "# Cr√©er une grille de sous-graphiques compacte\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(top_num_features):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    try:\n",
    "        # Diviser en quartiles et calculer m√©dianes\n",
    "        df['quartile'] = pd.qcut(df[feature], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'], duplicates='drop')\n",
    "        \n",
    "        # Donn√©es pour quartiers \"bad\" vs \"good\"\n",
    "        quartile_medians = []\n",
    "        quartiles_available = df['quartile'].unique()\n",
    "        quartiles_available = [q for q in quartiles_available if not pd.isna(q)]\n",
    "        \n",
    "        for q in sorted(quartiles_available):\n",
    "            q_data = df[df['quartile'] == q]\n",
    "            \n",
    "            med_bad = q_data[q_data['__is_bad__']]['SalePrice'].median()\n",
    "            med_good = q_data[~q_data['__is_bad__']]['SalePrice'].median()\n",
    "            \n",
    "            quartile_medians.append({\n",
    "                'quartile': q,\n",
    "                'median_bad': med_bad if not pd.isna(med_bad) else 0,\n",
    "                'median_good': med_good if not pd.isna(med_good) else 0\n",
    "            })\n",
    "        \n",
    "        plot_data = pd.DataFrame(quartile_medians)\n",
    "        \n",
    "        if len(plot_data) > 0:\n",
    "            # Graphique en barres c√¥te √† c√¥te\n",
    "            x = np.arange(len(plot_data))\n",
    "            width = 0.35\n",
    "            \n",
    "            bars1 = ax.bar(x - width/2, plot_data['median_good']/1000, width, \n",
    "                           label='Quartiers \"Good\"', color='lightgreen', alpha=0.8)\n",
    "            bars2 = ax.bar(x + width/2, plot_data['median_bad']/1000, width, \n",
    "                           label='Quartiers \"Bad\"', color='lightcoral', alpha=0.8)\n",
    "            \n",
    "            ax.set_xlabel(f'{feature} (par quartiles)')\n",
    "            ax.set_ylabel('Prix m√©dian (k$)')\n",
    "            ax.set_title(f'{feature}\\n(ŒîMAE: {num_summary[num_summary[\"feature\"] == feature][\"delta_mae\"].iloc[0]:+.0f}$)', \n",
    "                         fontsize=11, pad=10)\n",
    "            ax.set_xticks(x)\n",
    "            ax.set_xticklabels(plot_data['quartile'])\n",
    "            ax.legend(fontsize=9)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Annoter les valeurs sur les barres\n",
    "            for bar in bars1:\n",
    "                height = bar.get_height()\n",
    "                if height > 0:\n",
    "                    ax.text(bar.get_x() + bar.get_width()/2., height + 5,\n",
    "                           f'{height:.0f}k', ha='center', va='bottom', fontsize=8)\n",
    "            \n",
    "            for bar in bars2:\n",
    "                height = bar.get_height()\n",
    "                if height > 0:\n",
    "                    ax.text(bar.get_x() + bar.get_width()/2., height + 5,\n",
    "                           f'{height:.0f}k', ha='center', va='bottom', fontsize=8)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f'Pas de donn√©es\\npour {feature}', ha='center', va='center', transform=ax.transAxes)\n",
    "            \n",
    "    except Exception as e:\n",
    "        ax.text(0.5, 0.5, f'Erreur avec {feature}:\\n{str(e)[:30]}...', ha='center', va='center', transform=ax.transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(f'üìà M√©dianes SalePrice par Quartiles - TOP {TOP_K} Features Num√©riques Probl√©matiques', \n",
    "             fontsize=14, y=1.02)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° INTERPR√âTATION :\")\n",
    "print(\"   ‚Ä¢ Les barres rouges (quartiers 'Bad') montrent des patterns diff√©rents\")\n",
    "print(\"   ‚Ä¢ Plus l'√©cart entre rouge et vert est important, plus la feature est probl√©matique\")\n",
    "print(\"   ‚Ä¢ Cela explique pourquoi la MAE est √©lev√©e dans ces quartiers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "top-categorical-features", 
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELLULE 4 ‚Äî GRAPHIQUES LISIBLES POUR LES TOP_K FEATURES (CAT√âGORIELLES) =====\n",
    "\n",
    "print(f\"üìä VISUALISATION DES FEATURES CAT√âGORIELLES PROBL√âMATIQUES\\n\")\n",
    "\n",
    "# Prendre toutes les features cat√©gorielles\n",
    "top_cat_features = cat_summary['feature'].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(top_cat_features), figsize=(15, 6))\n",
    "if len(top_cat_features) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, feature in enumerate(top_cat_features):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    try:\n",
    "        # Calculer moyennes par modalit√©\n",
    "        modalite_means = []\n",
    "        categories = df[feature].unique()\n",
    "        \n",
    "        for cat in categories:\n",
    "            cat_data = df[df[feature] == cat]\n",
    "            \n",
    "            mean_bad = cat_data[cat_data['__is_bad__']]['SalePrice'].mean()\n",
    "            mean_good = cat_data[~cat_data['__is_bad__']]['SalePrice'].mean()\n",
    "            count_bad = cat_data[cat_data['__is_bad__']].shape[0]\n",
    "            count_good = cat_data[~cat_data['__is_bad__']].shape[0]\n",
    "            \n",
    "            modalite_means.append({\n",
    "                'category': cat,\n",
    "                'mean_bad': mean_bad if not pd.isna(mean_bad) else 0,\n",
    "                'mean_good': mean_good if not pd.isna(mean_good) else 0,\n",
    "                'count_bad': count_bad,\n",
    "                'count_good': count_good\n",
    "            })\n",
    "        \n",
    "        plot_data = pd.DataFrame(modalite_means)\n",
    "        # Trier par diff√©rence pour une meilleure lisibilit√©\n",
    "        plot_data['diff'] = plot_data['mean_bad'] - plot_data['mean_good']\n",
    "        plot_data = plot_data.sort_values('diff', ascending=True)\n",
    "        \n",
    "        # Ne garder que les modalit√©s avec suffisamment de donn√©es\n",
    "        plot_data = plot_data[(plot_data['count_bad'] >= 2) | (plot_data['count_good'] >= 5)]\n",
    "        \n",
    "        if len(plot_data) > 0:\n",
    "            x = np.arange(len(plot_data))\n",
    "            width = 0.35\n",
    "            \n",
    "            bars1 = ax.bar(x - width/2, plot_data['mean_good']/1000, width,\n",
    "                           label='Quartiers \"Good\"', color='lightgreen', alpha=0.8)\n",
    "            bars2 = ax.bar(x + width/2, plot_data['mean_bad']/1000, width,\n",
    "                           label='Quartiers \"Bad\"', color='lightcoral', alpha=0.8)\n",
    "            \n",
    "            ax.set_xlabel(f'Modalit√©s de {feature}')\n",
    "            ax.set_ylabel('Prix moyen (k$)')\n",
    "            ax.set_title(f'{feature}\\n(ŒîMAE: {cat_summary[cat_summary[\"feature\"] == feature][\"delta_mae\"].iloc[0]:+.0f}$)', \n",
    "                         fontsize=11, pad=10)\n",
    "            ax.set_xticks(x)\n",
    "            ax.set_xticklabels(plot_data['category'], rotation=45 if len(plot_data) > 4 else 0)\n",
    "            ax.legend(fontsize=9)\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Annoter les diff√©rences importantes\n",
    "            for i, (bar1, bar2) in enumerate(zip(bars1, bars2)):\n",
    "                height1 = bar1.get_height()\n",
    "                height2 = bar2.get_height()\n",
    "                diff = abs(height2 - height1)\n",
    "                \n",
    "                if diff > 20:  # Diff√©rence > 20k$\n",
    "                    max_height = max(height1, height2)\n",
    "                    ax.text(x[i], max_height + 10, f'Œî{diff:.0f}k',\n",
    "                           ha='center', va='bottom', fontsize=8, color='red', weight='bold')\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, f'Pas assez de donn√©es\\npour {feature}', ha='center', va='center', transform=ax.transAxes)\n",
    "            \n",
    "    except Exception as e:\n",
    "        ax.text(0.5, 0.5, f'Erreur avec {feature}:\\n{str(e)[:30]}...', ha='center', va='center', transform=ax.transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('üìä Prix Moyens par Modalit√© - Features Cat√©gorielles Probl√©matiques', \n",
    "             fontsize=14, y=1.02)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° INTERPR√âTATION :\")\n",
    "print(\"   ‚Ä¢ Les annotations rouges 'Œî' montrent les √©carts importants (>20k$)\")\n",
    "print(\"   ‚Ä¢ Ces √©carts expliquent pourquoi le mod√®le peine sur les quartiers 'Bad'\")\n",
    "print(\"   ‚Ä¢ Les m√™mes modalit√©s ont des prix tr√®s diff√©rents selon le quartier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "action-insights",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELLULE 5 ‚Äî PISTES D'ACTION, PAR QUARTIER \"BAD\" =====\n",
    "\n",
    "print(\"üöÄ RAPPORT D'ACTIONS PAR QUARTIER 'BAD'\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for quartier in bad_list:\n",
    "    print(f\"\\nüèòÔ∏è  QUARTIER : {quartier}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Donn√©es du quartier\n",
    "    quartier_data = df[df['Neighborhood'] == quartier]\n",
    "    mae_quartier = mae_by_neighborhood[quartier]\n",
    "    n_samples = len(quartier_data)\n",
    "    \n",
    "    print(f\"üìä MAE: {mae_quartier:,.0f}$ | √âchantillons: {n_samples} | √âcart vs MAE globale: {mae_quartier - mae_global:+,.0f}$\")\n",
    "    \n",
    "    # Analyser les top features probl√©matiques pour ce quartier\n",
    "    print(\"\\nüîç CARACT√âRISTIQUES PROBL√âMATIQUES :\")\n",
    "    \n",
    "    # Top 3 features num√©riques\n",
    "    print(\"\\n   üìà Features num√©riques :\")\n",
    "    for feature in top_num_features[:3]:\n",
    "        if feature in quartier_data.columns:\n",
    "            quartier_median = quartier_data[feature].median()\n",
    "            global_median = df[feature].median()\n",
    "            diff_pct = ((quartier_median - global_median) / global_median * 100) if global_median != 0 else 0\n",
    "            \n",
    "            # Quartile du quartier par rapport √† la population globale\n",
    "            try:\n",
    "                quartile_pos = pd.qcut(df[feature], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'], duplicates='drop')\n",
    "                quartier_quartile = quartile_pos.iloc[quartier_data.index[0]] if len(quartier_data.index) > 0 else 'N/A'\n",
    "            except:\n",
    "                quartier_quartile = 'N/A'\n",
    "            \n",
    "            delta_mae_feature = num_summary[num_summary['feature'] == feature]['delta_mae'].iloc[0]\n",
    "            \n",
    "            print(f\"      ‚Ä¢ {feature}: m√©diane {quartier_median:.0f} ({diff_pct:+.1f}% vs global) \")\n",
    "            print(f\"        ‚Üí Position: {quartier_quartile} | Impact ŒîMAE: {delta_mae_feature:+,.0f}$\")\n",
    "    \n",
    "    # Features cat√©gorielles\n",
    "    print(\"\\n   üè∑Ô∏è  Features cat√©gorielles :\")\n",
    "    for feature in top_cat_features:\n",
    "        if feature != 'Neighborhood' and feature in quartier_data.columns:  \n",
    "            # Distribution des modalit√©s dans ce quartier\n",
    "            quartier_dist = quartier_data[feature].value_counts(normalize=True)\n",
    "            global_dist = df[feature].value_counts(normalize=True)\n",
    "            \n",
    "            if len(quartier_dist) > 0:\n",
    "                # Modalit√© la plus fr√©quente dans ce quartier\n",
    "                top_modalite = quartier_dist.index[0]\n",
    "                quartier_freq = quartier_dist.iloc[0] * 100\n",
    "                global_freq = global_dist.get(top_modalite, 0) * 100\n",
    "                \n",
    "                delta_mae_feature = cat_summary[cat_summary['feature'] == feature]['delta_mae'].iloc[0]\n",
    "                \n",
    "                print(f\"      ‚Ä¢ {feature}: modalit√© dominante '{top_modalite}' ({quartier_freq:.0f}% vs {global_freq:.0f}% global)\")\n",
    "                print(f\"        ‚Üí Impact ŒîMAE: {delta_mae_feature:+,.0f}$\")\n",
    "    \n",
    "    # Recommandations sp√©cifiques\n",
    "    print(\"\\nüí° RECOMMANDATIONS :\")\n",
    "    \n",
    "    # Recommandation bas√©e sur la feature la plus probl√©matique\n",
    "    if len(num_summary) > 0:\n",
    "        top_problematic = num_summary.iloc[0]['feature']\n",
    "        top_delta = num_summary.iloc[0]['delta_mae']\n",
    "        \n",
    "        if top_delta > 5000:\n",
    "            print(f\"   1. üéØ PRIORIT√â HAUTE: Am√©liorer la mod√©lisation pour '{top_problematic}'\")\n",
    "            print(f\"      ‚Üí Ajouter des interactions sp√©cifiques au quartier {quartier}\")\n",
    "            \n",
    "    if mae_quartier > mae_global * 1.5:\n",
    "        print(f\"   2. üìä Collecter plus de donn√©es pour ce quartier (seulement {n_samples} √©chantillons)\")\n",
    "        \n",
    "    if len(quartier_data) < 20:\n",
    "        print(f\"   3. ‚ö†Ô∏è  Quartier sous-repr√©sent√©: consid√©rer un regroupement avec quartiers similaires\")\n",
    "    \n",
    "    # Recommandation bas√©e sur les features cat√©gorielles\n",
    "    if len(cat_summary) > 0:\n",
    "        top_cat_problematic = cat_summary.iloc[0]['feature'] \n",
    "        if cat_summary.iloc[0]['delta_mae'] > 3000:\n",
    "            print(f\"   4. üè∑Ô∏è  Feature cat√©gorielle '{top_cat_problematic}': cr√©er encodage sp√©cifique au quartier\")\n",
    "    \n",
    "    print(f\"   5. üîß Envisager un mod√®le sp√©cialis√© pour les quartiers √† haute variabilit√©\")\n",
    "\n",
    "print(f\"\\n\\nüìã R√âSUM√â GLOBAL DES ACTIONS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"üéØ {len(bad_list)} quartiers identifi√©s comme probl√©matiques\")\n",
    "if len(num_summary) > 0:\n",
    "    print(f\"üìä Feature num√©rique prioritaire: {num_summary.iloc[0]['feature']} (ŒîMAE: {num_summary.iloc[0]['delta_mae']:+,.0f}$)\")\n",
    "if len(cat_summary) > 0:\n",
    "    print(f\"üè∑Ô∏è  Feature cat√©gorielle prioritaire: {cat_summary.iloc[0]['feature']} (ŒîMAE: {cat_summary.iloc[0]['delta_mae']:+,.0f}$)\")\n",
    "print(f\"\\n‚úÖ Analyse termin√©e. Prochaines √©tapes: impl√©menter les am√©liorations sugg√©r√©es.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regression-prediction-prix-immobilier-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}