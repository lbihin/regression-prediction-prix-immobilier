{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "908b1e39",
   "metadata": {},
   "source": [
    "# Regression Prix Immobilier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "764d0632",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 5000)\n",
    "pd.set_option(\"display.max_rows\", 101)\n",
    "pd.set_option('display.float_format', lambda x: '{:.2f}'.format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-analysis-title",
   "metadata": {},
   "source": [
    "# ğŸ“Š Analyse SimplifiÃ©e des Quartiers \"Bad\" (MAE Ã‰levÃ©e)\n",
    "\n",
    "Cette section contient l'analyse refactorisÃ©e et simplifiÃ©e pour identifier pourquoi certains quartiers ont une erreur de prÃ©diction Ã©levÃ©e (MAE). \n",
    "\n",
    "**Structure en 5 cellules comme demandÃ© :**\n",
    "1. **Contexte et prÃ©paration** : Chargement des donnÃ©es et dÃ©finition des groupes de comparaison\n",
    "2. **MÃ©triques simples (Î”MAE) et tableaux rÃ©cap** : Calcul des MAE pour les caractÃ©ristiques numÃ©riques et catÃ©gorielles  \n",
    "3. **Graphiques lisibles pour les TOP_K features (numÃ©riques)** : Visualisation des mÃ©dianes de SalePrice par quantile\n",
    "4. **Graphiques lisibles pour les TOP_K features (catÃ©gorielles)** : Visualisation des moyennes de SalePrice par modalitÃ©\n",
    "5. **Pistes d'action, par quartier \"bad\"** : Rapport textuel sur les caractÃ©ristiques qui pÃ©nalisent la MAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "context-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELLULE 1 â€” CONTEXTE ET PRÃ‰PARATION =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration des graphiques pour plus de lisibilitÃ©\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Charger les donnÃ©es d'analyse\n",
    "df = pd.read_csv(\"./data/kaggle_train_set.csv\")\n",
    "print(f\"ğŸ“Š Dataset chargÃ© : {df.shape[0]} Ã©chantillons, {df.shape[1]} variables\")\n",
    "\n",
    "# EntraÃ®ner un modÃ¨le simple pour calculer les MAE par quartier\n",
    "features_for_model = ['OverallQual', 'YearBuilt', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', \n",
    "                     'FullBath', 'TotRmsAbvGrd', 'Fireplaces', 'YearRemodAdd', 'GarageArea', '1stFlrSF']\n",
    "\n",
    "# Encoder les variables catÃ©gorielles pour le modÃ¨le\n",
    "df_model = df.copy()\n",
    "le_neighb = LabelEncoder()\n",
    "le_exter = LabelEncoder() \n",
    "le_kitchen = LabelEncoder()\n",
    "\n",
    "df_model['Neighborhood_enc'] = le_neighb.fit_transform(df_model['Neighborhood'])\n",
    "df_model['ExterQual_enc'] = le_exter.fit_transform(df_model['ExterQual'])\n",
    "df_model['KitchenQual_enc'] = le_kitchen.fit_transform(df_model['KitchenQual'])\n",
    "\n",
    "X = df_model[features_for_model + ['Neighborhood_enc', 'ExterQual_enc', 'KitchenQual_enc']]\n",
    "y = df_model['SalePrice']\n",
    "\n",
    "# Diviser les donnÃ©es\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# EntraÃ®ner le modÃ¨le\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Faire les prÃ©dictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculer la MAE globale\n",
    "mae_global = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"ğŸ¯ MAE globale du modÃ¨le : {mae_global:,.0f}$\")\n",
    "\n",
    "# CrÃ©er un DataFrame avec les rÃ©sultats de test\n",
    "test_results = pd.DataFrame({\n",
    "    'Neighborhood': df.iloc[X_test.index]['Neighborhood'].values,\n",
    "    'SalePrice_true': y_test.values,\n",
    "    'SalePrice_pred': y_pred,\n",
    "    'residual': y_test.values - y_pred\n",
    "})\n",
    "\n",
    "# Calculer la MAE par quartier\n",
    "mae_by_neighborhood = test_results.groupby('Neighborhood').apply(\n",
    "    lambda x: mean_absolute_error(x['SalePrice_true'], x['SalePrice_pred'])\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print(f\"\\nğŸ˜ï¸  Quartiers avec MAE la plus Ã©levÃ©e :\")\n",
    "print(mae_by_neighborhood.head(8))\n",
    "\n",
    "# DÃ©finir les quartiers \"bad\" (MAE > percentile 75)\n",
    "mae_threshold = mae_by_neighborhood.quantile(0.75)\n",
    "bad_mae_region = mae_by_neighborhood[mae_by_neighborhood > mae_threshold].index.tolist()\n",
    "print(f\"\\nğŸš¨ Quartiers 'BAD' identifiÃ©s (MAE > {mae_threshold:,.0f}$) :\")\n",
    "for region in bad_mae_region:\n",
    "    count = df[df['Neighborhood'] == region].shape[0]\n",
    "    print(f\"   - {region}: MAE = {mae_by_neighborhood[region]:,.0f}$ ({count} Ã©chantillons)\")\n",
    "\n",
    "# CrÃ©er le flag pour l'analyse comparative\n",
    "bad_list = [n for n in bad_mae_region if n in df[\"Neighborhood\"].unique()]\n",
    "df[\"__is_bad__\"] = df[\"Neighborhood\"].isin(bad_list)\n",
    "\n",
    "print(f\"\\nâœ… PrÃ©paration terminÃ©e. {len(bad_list)} quartiers 'bad' identifiÃ©s pour analyse.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELLULE 2 â€” MÃ‰TRIQUES SIMPLES (Î”MAE) ET TABLEAUX RÃ‰CAP =====\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    \"\"\"Fonction MAE simple\"\"\"\n",
    "    return np.abs(y_true - y_pred).mean()\n",
    "\n",
    "print(\"ğŸ“‹ CALCUL DES Î”MAE POUR TOUTES LES CARACTÃ‰RISTIQUES\\n\")\n",
    "\n",
    "# === FEATURES NUMÃ‰RIQUES ===\n",
    "num_features = ['OverallQual', 'YearBuilt', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', \n",
    "                'FullBath', 'TotRmsAbvGrd', 'Fireplaces', 'YearRemodAdd', 'GarageArea', \n",
    "                'LotArea', '1stFlrSF']\n",
    "\n",
    "# Calculer la prÃ©diction \"naÃ¯ve\" : mÃ©diane globale par quartile de feature\n",
    "rows_num = []\n",
    "for f in num_features:\n",
    "    # Diviser en quartiles\n",
    "    df['quartile'] = pd.qcut(df[f], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "    \n",
    "    # Pour chaque quartile, prÃ©dire avec la mÃ©diane du quartile\n",
    "    predictions_out = []\n",
    "    predictions_bad = []\n",
    "    actual_out = []\n",
    "    actual_bad = []\n",
    "    \n",
    "    for quartile in ['Q1', 'Q2', 'Q3', 'Q4']:\n",
    "        quartile_data = df[df['quartile'] == quartile]\n",
    "        median_price = quartile_data['SalePrice'].median()\n",
    "        \n",
    "        # SÃ©parer quartiers \"bad\" vs \"good\"\n",
    "        out_data = quartile_data[~quartile_data['__is_bad__']]\n",
    "        bad_data = quartile_data[quartile_data['__is_bad__']]\n",
    "        \n",
    "        if len(out_data) > 0:\n",
    "            predictions_out.extend([median_price] * len(out_data))\n",
    "            actual_out.extend(out_data['SalePrice'].tolist())\n",
    "        \n",
    "        if len(bad_data) > 0:\n",
    "            predictions_bad.extend([median_price] * len(bad_data))\n",
    "            actual_bad.extend(bad_data['SalePrice'].tolist())\n",
    "    \n",
    "    # Calculer les MAE\n",
    "    mae_out = mae(actual_out, predictions_out) if actual_out else 0\n",
    "    mae_bad = mae(actual_bad, predictions_bad) if actual_bad else 0\n",
    "    delta_mae = mae_bad - mae_out\n",
    "    \n",
    "    rows_num.append({\n",
    "        \"feature\": f,\n",
    "        \"mae_out\": mae_out,\n",
    "        \"mae_bad\": mae_bad,\n",
    "        \"delta_mae\": delta_mae\n",
    "    })\n",
    "\n",
    "num_summary = pd.DataFrame(rows_num).sort_values(\"delta_mae\", ascending=False)\n",
    "\n",
    "print(\"ğŸ”¢ RÃ‰SUMÃ‰ FEATURES NUMÃ‰RIQUES (Top 8 Î”MAE)\")\n",
    "print(\"=\"*60)\n",
    "display(num_summary.head(8).round(0))\n",
    "\n",
    "# === FEATURES CATÃ‰GORIELLES ===\n",
    "cat_features = ['ExterQual', 'KitchenQual', 'Neighborhood']\n",
    "\n",
    "rows_cat = []\n",
    "for f in cat_features:\n",
    "    # Pour chaque modalitÃ©, prÃ©dire avec la moyenne de cette modalitÃ©\n",
    "    predictions_out = []\n",
    "    predictions_bad = []\n",
    "    actual_out = []\n",
    "    actual_bad = []\n",
    "    \n",
    "    for category in df[f].unique():\n",
    "        cat_data = df[df[f] == category]\n",
    "        mean_price = cat_data['SalePrice'].mean()\n",
    "        \n",
    "        # SÃ©parer quartiers \"bad\" vs \"good\"\n",
    "        out_data = cat_data[~cat_data['__is_bad__']]\n",
    "        bad_data = cat_data[cat_data['__is_bad__']]\n",
    "        \n",
    "        if len(out_data) > 0:\n",
    "            predictions_out.extend([mean_price] * len(out_data))\n",
    "            actual_out.extend(out_data['SalePrice'].tolist())\n",
    "        \n",
    "        if len(bad_data) > 0:\n",
    "            predictions_bad.extend([mean_price] * len(bad_data))\n",
    "            actual_bad.extend(bad_data['SalePrice'].tolist())\n",
    "    \n",
    "    # Calculer les MAE\n",
    "    mae_out = mae(actual_out, predictions_out) if actual_out else 0\n",
    "    mae_bad = mae(actual_bad, predictions_bad) if actual_bad else 0\n",
    "    delta_mae = mae_bad - mae_out\n",
    "    \n",
    "    rows_cat.append({\n",
    "        \"feature\": f,\n",
    "        \"mae_out\": mae_out,\n",
    "        \"mae_bad\": mae_bad,\n",
    "        \"delta_mae\": delta_mae\n",
    "    })\n",
    "\n",
    "cat_summary = pd.DataFrame(rows_cat).sort_values(\"delta_mae\", ascending=False)\n",
    "\n",
    "print(\"\\nğŸ·ï¸  RÃ‰SUMÃ‰ FEATURES CATÃ‰GORIELLES\")\n",
    "print(\"=\"*60)\n",
    "display(cat_summary.round(0))\n",
    "\n",
    "print(f\"\\nğŸ’¡ INSIGHTS Î”MAE :\")\n",
    "print(f\"   â€¢ Feature numÃ©rique la plus problÃ©matique : {num_summary.iloc[0]['feature']} (Î”MAE: {num_summary.iloc[0]['delta_mae']:+,.0f}$)\")\n",
    "print(f\"   â€¢ Feature catÃ©gorielle la plus problÃ©matique : {cat_summary.iloc[0]['feature']} (Î”MAE: {cat_summary.iloc[0]['delta_mae']:+,.0f}$)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "top-numerical-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELLULE 3 â€” GRAPHIQUES LISIBLES POUR LES TOP_K FEATURES (NUMÃ‰RIQUES) =====\n",
    "\n",
    "TOP_K = 6  # Nombre de features Ã  visualiser\n",
    "top_num_features = num_summary.head(TOP_K)['feature'].tolist()\n",
    "\n",
    "print(f\"ğŸ“Š VISUALISATION DES {TOP_K} FEATURES NUMÃ‰RIQUES LES PLUS PROBLÃ‰MATIQUES\\n\")\n",
    "\n",
    "# CrÃ©er une grille de sous-graphiques compacte\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(top_num_features):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Diviser en quartiles et calculer mÃ©dianes\n",
    "    df['quartile'] = pd.qcut(df[feature], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "    \n",
    "    # DonnÃ©es pour quartiers \"bad\" vs \"good\"\n",
    "    quartile_medians = []\n",
    "    quartiles = ['Q1', 'Q2', 'Q3', 'Q4']\n",
    "    \n",
    "    for q in quartiles:\n",
    "        q_data = df[df['quartile'] == q]\n",
    "        \n",
    "        med_bad = q_data[q_data['__is_bad__']]['SalePrice'].median()\n",
    "        med_good = q_data[~q_data['__is_bad__']]['SalePrice'].median()\n",
    "        \n",
    "        quartile_medians.append({\n",
    "            'quartile': q,\n",
    "            'median_bad': med_bad if not pd.isna(med_bad) else 0,\n",
    "            'median_good': med_good if not pd.isna(med_good) else 0\n",
    "        })\n",
    "    \n",
    "    plot_data = pd.DataFrame(quartile_medians)\n",
    "    \n",
    "    # Graphique en barres cÃ´te Ã  cÃ´te\n",
    "    x = np.arange(len(quartiles))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, plot_data['median_good']/1000, width, \n",
    "                   label='Quartiers \"Good\"', color='lightgreen', alpha=0.8)\n",
    "    bars2 = ax.bar(x + width/2, plot_data['median_bad']/1000, width, \n",
    "                   label='Quartiers \"Bad\"', color='lightcoral', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel(f'{feature} (par quartiles)')\n",
    "    ax.set_ylabel('Prix mÃ©dian (k$)')\n",
    "    ax.set_title(f'{feature}\\n(Î”MAE: {num_summary[num_summary[\"feature\"] == feature][\"delta_mae\"].iloc[0]:+.0f}$)', \n",
    "                 fontsize=11, pad=10)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(quartiles)\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Annoter les valeurs sur les barres\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 5,\n",
    "                   f'{height:.0f}k', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 5,\n",
    "                   f'{height:.0f}k', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(f'ğŸ“ˆ MÃ©dianes SalePrice par Quartiles - TOP {TOP_K} Features NumÃ©riques ProblÃ©matiques', \n",
    "             fontsize=14, y=1.02)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ INTERPRÃ‰TATION :\")\n",
    "print(\"   â€¢ Les barres rouges (quartiers 'Bad') montrent des patterns diffÃ©rents\")\n",
    "print(\"   â€¢ Plus l'Ã©cart entre rouge et vert est important, plus la feature est problÃ©matique\")\n",
    "print(\"   â€¢ Cela explique pourquoi la MAE est Ã©levÃ©e dans ces quartiers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "top-categorical-features", 
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELLULE 4 â€” GRAPHIQUES LISIBLES POUR LES TOP_K FEATURES (CATÃ‰GORIELLES) =====\n",
    "\n",
    "print(f\"ğŸ“Š VISUALISATION DES FEATURES CATÃ‰GORIELLES PROBLÃ‰MATIQUES\\n\")\n",
    "\n",
    "# Prendre toutes les features catÃ©gorielles\n",
    "top_cat_features = cat_summary['feature'].tolist()\n",
    "\n",
    "fig, axes = plt.subplots(1, len(top_cat_features), figsize=(15, 6))\n",
    "if len(top_cat_features) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, feature in enumerate(top_cat_features):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Calculer moyennes par modalitÃ©\n",
    "    modalite_means = []\n",
    "    categories = df[feature].unique()\n",
    "    \n",
    "    for cat in categories:\n",
    "        cat_data = df[df[feature] == cat]\n",
    "        \n",
    "        mean_bad = cat_data[cat_data['__is_bad__']]['SalePrice'].mean()\n",
    "        mean_good = cat_data[~cat_data['__is_bad__']]['SalePrice'].mean()\n",
    "        count_bad = cat_data[cat_data['__is_bad__']].shape[0]\n",
    "        count_good = cat_data[~cat_data['__is_bad__']].shape[0]\n",
    "        \n",
    "        modalite_means.append({\n",
    "            'category': cat,\n",
    "            'mean_bad': mean_bad if not pd.isna(mean_bad) else 0,\n",
    "            'mean_good': mean_good if not pd.isna(mean_good) else 0,\n",
    "            'count_bad': count_bad,\n",
    "            'count_good': count_good\n",
    "        })\n",
    "    \n",
    "    plot_data = pd.DataFrame(modalite_means)\n",
    "    # Trier par diffÃ©rence pour une meilleure lisibilitÃ©\n",
    "    plot_data['diff'] = plot_data['mean_bad'] - plot_data['mean_good']\n",
    "    plot_data = plot_data.sort_values('diff', ascending=True)\n",
    "    \n",
    "    # Ne garder que les modalitÃ©s avec suffisamment de donnÃ©es\n",
    "    plot_data = plot_data[(plot_data['count_bad'] >= 3) | (plot_data['count_good'] >= 3)]\n",
    "    \n",
    "    if len(plot_data) > 0:\n",
    "        x = np.arange(len(plot_data))\n",
    "        width = 0.35\n",
    "        \n",
    "        bars1 = ax.bar(x - width/2, plot_data['mean_good']/1000, width,\n",
    "                       label='Quartiers \"Good\"', color='lightgreen', alpha=0.8)\n",
    "        bars2 = ax.bar(x + width/2, plot_data['mean_bad']/1000, width,\n",
    "                       label='Quartiers \"Bad\"', color='lightcoral', alpha=0.8)\n",
    "        \n",
    "        ax.set_xlabel(f'ModalitÃ©s de {feature}')\n",
    "        ax.set_ylabel('Prix moyen (k$)')\n",
    "        ax.set_title(f'{feature}\\n(Î”MAE: {cat_summary[cat_summary[\"feature\"] == feature][\"delta_mae\"].iloc[0]:+.0f}$)', \n",
    "                     fontsize=11, pad=10)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(plot_data['category'], rotation=45 if len(plot_data) > 4 else 0)\n",
    "        ax.legend(fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Annoter les diffÃ©rences importantes\n",
    "        for i, (bar1, bar2) in enumerate(zip(bars1, bars2)):\n",
    "            height1 = bar1.get_height()\n",
    "            height2 = bar2.get_height()\n",
    "            diff = abs(height2 - height1)\n",
    "            \n",
    "            if diff > 20:  # DiffÃ©rence > 20k$\n",
    "                max_height = max(height1, height2)\n",
    "                ax.text(x[i], max_height + 10, f'Î”{diff:.0f}k',\n",
    "                       ha='center', va='bottom', fontsize=8, color='red', weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('ğŸ“Š Prix Moyens par ModalitÃ© - Features CatÃ©gorielles ProblÃ©matiques', \n",
    "             fontsize=14, y=1.02)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ INTERPRÃ‰TATION :\")\n",
    "print(\"   â€¢ Les annotations rouges 'Î”' montrent les Ã©carts importants (>20k$)\")\n",
    "print(\"   â€¢ Ces Ã©carts expliquent pourquoi le modÃ¨le peine sur les quartiers 'Bad'\")\n",
    "print(\"   â€¢ Les mÃªmes modalitÃ©s ont des prix trÃ¨s diffÃ©rents selon le quartier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "action-insights",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== CELLULE 5 â€” PISTES D'ACTION, PAR QUARTIER \"BAD\" =====\n",
    "\n",
    "print(\"ğŸš€ RAPPORT D'ACTIONS PAR QUARTIER 'BAD'\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for quartier in bad_list:\n",
    "    print(f\"\\nğŸ˜ï¸  QUARTIER : {quartier}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # DonnÃ©es du quartier\n",
    "    quartier_data = df[df['Neighborhood'] == quartier]\n",
    "    mae_quartier = mae_by_neighborhood[quartier]\n",
    "    n_samples = len(quartier_data)\n",
    "    \n",
    "    print(f\"ğŸ“Š MAE: {mae_quartier:,.0f}$ | Ã‰chantillons: {n_samples} | Ã‰cart vs MAE globale: {mae_quartier - mae_global:+,.0f}$\")\n",
    "    \n",
    "    # Analyser les top features problÃ©matiques pour ce quartier\n",
    "    print(\"\\nğŸ” CARACTÃ‰RISTIQUES PROBLÃ‰MATIQUES :\")\n",
    "    \n",
    "    # Top 3 features numÃ©riques\n",
    "    print(\"\\n   ğŸ“ˆ Features numÃ©riques :\")\n",
    "    for feature in top_num_features[:3]:\n",
    "        quartier_median = quartier_data[feature].median()\n",
    "        global_median = df[feature].median()\n",
    "        diff_pct = ((quartier_median - global_median) / global_median * 100) if global_median != 0 else 0\n",
    "        \n",
    "        # Quartile du quartier par rapport Ã  la population globale\n",
    "        quartile_pos = pd.qcut(df[feature], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "        quartier_quartile = pd.qcut(df[feature], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4']).iloc[quartier_data.index[0]]\n",
    "        \n",
    "        delta_mae_feature = num_summary[num_summary['feature'] == feature]['delta_mae'].iloc[0]\n",
    "        \n",
    "        print(f\"      â€¢ {feature}: mÃ©diane {quartier_median:.0f} ({diff_pct:+.1f}% vs global) \")\n",
    "        print(f\"        â†’ Position: {quartier_quartile} | Impact Î”MAE: {delta_mae_feature:+,.0f}$\")\n",
    "    \n",
    "    # Features catÃ©gorielles\n",
    "    print(\"\\n   ğŸ·ï¸  Features catÃ©gorielles :\")\n",
    "    for feature in top_cat_features:\n",
    "        if feature != 'Neighborhood':  # Skip neighborhood car c'est le quartier analysÃ©\n",
    "            # Distribution des modalitÃ©s dans ce quartier\n",
    "            quartier_dist = quartier_data[feature].value_counts(normalize=True)\n",
    "            global_dist = df[feature].value_counts(normalize=True)\n",
    "            \n",
    "            # ModalitÃ© la plus frÃ©quente dans ce quartier\n",
    "            top_modalite = quartier_dist.index[0]\n",
    "            quartier_freq = quartier_dist.iloc[0] * 100\n",
    "            global_freq = global_dist.get(top_modalite, 0) * 100\n",
    "            \n",
    "            delta_mae_feature = cat_summary[cat_summary['feature'] == feature]['delta_mae'].iloc[0]\n",
    "            \n",
    "            print(f\"      â€¢ {feature}: modalitÃ© dominante '{top_modalite}' ({quartier_freq:.0f}% vs {global_freq:.0f}% global)\")\n",
    "            print(f\"        â†’ Impact Î”MAE: {delta_mae_feature:+,.0f}$\")\n",
    "    \n",
    "    # Recommandations spÃ©cifiques\n",
    "    print(\"\\nğŸ’¡ RECOMMANDATIONS :\")\n",
    "    \n",
    "    # Recommandation basÃ©e sur la feature la plus problÃ©matique\n",
    "    top_problematic = num_summary.iloc[0]['feature']\n",
    "    top_delta = num_summary.iloc[0]['delta_mae']\n",
    "    \n",
    "    if top_delta > 5000:\n",
    "        print(f\"   1. ğŸ¯ PRIORITÃ‰ HAUTE: AmÃ©liorer la modÃ©lisation pour '{top_problematic}'\")\n",
    "        print(f\"      â†’ Ajouter des interactions spÃ©cifiques au quartier {quartier}\")\n",
    "        \n",
    "    if mae_quartier > mae_global * 1.5:\n",
    "        print(f\"   2. ğŸ“Š Collecter plus de donnÃ©es pour ce quartier (seulement {n_samples} Ã©chantillons)\")\n",
    "        \n",
    "    if len(quartier_data) < 20:\n",
    "        print(f\"   3. âš ï¸  Quartier sous-reprÃ©sentÃ©: considÃ©rer un regroupement avec quartiers similaires\")\n",
    "    \n",
    "    # Recommandation basÃ©e sur les features catÃ©gorielles\n",
    "    top_cat_problematic = cat_summary.iloc[0]['feature'] \n",
    "    if cat_summary.iloc[0]['delta_mae'] > 3000:\n",
    "        print(f\"   4. ğŸ·ï¸  Feature catÃ©gorielle '{top_cat_problematic}': crÃ©er encodage spÃ©cifique au quartier\")\n",
    "    \n",
    "    print(f\"   5. ğŸ”§ Envisager un modÃ¨le spÃ©cialisÃ© pour les quartiers Ã  haute variabilitÃ©\")\n",
    "\n",
    "print(f\"\\n\\nğŸ“‹ RÃ‰SUMÃ‰ GLOBAL DES ACTIONS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"ğŸ¯ {len(bad_list)} quartiers identifiÃ©s comme problÃ©matiques\")\n",
    "print(f\"ğŸ“Š Feature numÃ©rique prioritaire: {num_summary.iloc[0]['feature']} (Î”MAE: {num_summary.iloc[0]['delta_mae']:+,.0f}$)\")\n",
    "print(f\"ğŸ·ï¸  Feature catÃ©gorielle prioritaire: {cat_summary.iloc[0]['feature']} (Î”MAE: {cat_summary.iloc[0]['delta_mae']:+,.0f}$)\")\n",
    "print(f\"\\nâœ… Analyse terminÃ©e. Prochaines Ã©tapes: implÃ©menter les amÃ©liorations suggÃ©rÃ©es.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regression-prediction-prix-immobilier-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}